{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a74e92f",
   "metadata": {},
   "source": [
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pylib as py\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tf2lib as tl\n",
    "import tf2gan as gan\n",
    "import tqdm\n",
    "import scipy as sc\n",
    "import scipy.io\n",
    "import os\n",
    "import matplotlib.pyplot as pyplot\n",
    "import data\n",
    "import module\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# specify the gpu to be utilized\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c0b1f",
   "metadata": {},
   "source": [
    "## define the data and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size\n",
    "height_crop_size = 160 \n",
    "width_crop_size = 64\n",
    "slice_size = 52\n",
    "\n",
    "# model training parameters\n",
    "batch_size = 1\n",
    "epochs = 100\n",
    "epoch_decay = epochs // 2 # number of epoch to start decaying the learning rate\n",
    "\n",
    "# cycleGAN parameters\n",
    "lr = 0.0002 # learning rate\n",
    "beta_1 = 0.5 # weight\n",
    "adversarial_loss_mode = 'lsgan' # choices = ['gan', 'hinge_v1', 'hinge_v2', 'lsgan', 'wgan']\n",
    "gradient_penalty_mode = 'none' # choices = ['none', 'dragan', 'wgan-gp']\n",
    "gradient_penalty_weight = 10.0\n",
    "cycle_loss_weight = 10.0\n",
    "identity_loss_weight = 2.0\n",
    "pool_size = 50 # pool size of fake samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dba5cb3",
   "metadata": {},
   "source": [
    "## Load the training and test data sets\n",
    "\n",
    "The data for each set consists of 909 images of 3D aortic anatomy, which were either obtained using CT angiography or 4D flow MRI. The peak systolic velocity for each set was also measured using 4D flow MRI. The anatomy and flow data have been pre-processed and are each sized at 192 x 64 x 64 pixels, representing the height, width, and slice dimensions, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the mapping parser in tensorflow dataset pipline\n",
    "def parser(tfrecord):\n",
    "    feature = tf.io.parse_single_example(tfrecord,{'A': tf.io.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "              'B' : tf.io.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "              'height' : tf.io.FixedLenFeature(shape=[], dtype=tf.int64),\n",
    "              'width'  : tf.io.FixedLenFeature(shape=[], dtype=tf.int64),\n",
    "              'depth'  : tf.io.FixedLenFeature(shape=[], dtype=tf.int64)})\n",
    "    height = tf.cast(feature[\"height\"], tf.int32)\n",
    "    width  = tf.cast(feature[\"width\"], tf.int32)\n",
    "    depth  = tf.cast(feature[\"depth\"], tf.int32)\n",
    "    A = tf.io.decode_raw(feature['A'], tf.float32) \n",
    "    A = tf.reshape(A, [height, width, depth])\n",
    "    A = tl.center_crop(A, [height_crop_size,width_crop_size])\n",
    "    B = tf.io.decode_raw(feature['B'], tf.float32) \n",
    "    B = tf.reshape(B, [height, width, depth])\n",
    "    B = tl.center_crop(B, [height_crop_size,width_crop_size])\n",
    "    return A, B\n",
    "\n",
    "# training set directory\n",
    "tfrecord_path = 'anatomay2flow_train.tfrecords'\n",
    "dataset_train = tf.data.TFRecordDataset(tfrecord_path)\n",
    "dataset_train = dataset_train.map(map_func=parser)\n",
    "data_size = len(list(dataset_train))\n",
    "dataset_train = dataset_train.shuffle(buffer_size=data_size)\n",
    "dataset_train = dataset_train.batch(batch_size)\n",
    "len_dataset = int(data_size/batch_size)\n",
    "\n",
    "# test set directory\n",
    "tfrecord_path = 'anatomay2flow_test.tfrecords'\n",
    "dataset_test = tf.data.TFRecordDataset(tfrecord_path)\n",
    "dataset_test = dataset_test.map(map_func=parser)\n",
    "dataset_test = dataset_test.batch(1)\n",
    "dataset_test = iter(dataset_test);\n",
    "\n",
    "# create a batch of test sample to monitor the model performance while training\n",
    "Asample = list()\n",
    "Bsample = list()\n",
    "ii = 0\n",
    "for a,b in dataset_test:\n",
    "    Asample.append(a)\n",
    "    Bsample.append(b)\n",
    "    ii+=1\n",
    "    if ii>9:\n",
    "        print(a.shape)\n",
    "        break\n",
    "        \n",
    "# plot example images\n",
    "n_samples = len(Asample)\n",
    "pyplot.figure(figsize=(4,40))\n",
    "for i in range(1,n_samples+1):\n",
    "    anatomy = np.squeeze(Asample[i-1])\n",
    "    pyplot.subplot(n_samples,2,2*i-1)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(np.mean(anatomy,axis=-1),cmap='jet')\n",
    "    # plot target image\n",
    "for i in range(1,n_samples+1):\n",
    "    flow = np.squeeze(Bsample[i-1])\n",
    "    pyplot.subplot(n_samples,2,2*i)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(np.mean(flow,axis=-1),cmap='jet')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6614a7c",
   "metadata": {},
   "source": [
    "## define the generators and discriminators\n",
    "\n",
    "The CycleGAN involves the simultaneous training of two generator models and two discriminator models. One generator takes images from the CT domain as input and outputs images for the MRI domain, and the other generator takes images from the MRI domain as input and generates images for the CT domain. Discriminator models are then used to determine how plausible the generated images are and update the generator models accordingly.\n",
    "\n",
    "### generator\n",
    "The generator is an encoder-decoder model architecture. The model takes a CT image and generates a MRI image. It does this by first downsampling or encoding the CT image down to a bottleneck layer, then interpreting the encoding with a number of ResNet layers that use skip connections, followed by a series of layers that up sample or decode the representation to the size of the MRI data.\n",
    "    \n",
    "### discriminator\n",
    "The discriminator design is based on the effective receptive field of the model, which defines the relationship between one output of the model to the number of pixels in the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the different normalization options\n",
    "def _get_norm_layer(norm):\n",
    "    if norm == 'none':\n",
    "        return lambda: lambda x: x\n",
    "    elif norm == 'batch_norm':\n",
    "        return keras.layers.BatchNormalization\n",
    "    elif norm == 'instance_norm':\n",
    "        return tfa.layers.InstanceNormalization\n",
    "    elif norm == 'layer_norm':\n",
    "        return keras.layers.LayerNormalization\n",
    "\n",
    "# define the resnet generators\n",
    "def ResnetGenerator(input_shape=(None, None, None, 1),\n",
    "                    output_channels=1,\n",
    "                    dim=64,\n",
    "                    n_downsamplings=2,\n",
    "                    n_blocks=9,\n",
    "                    norm='instance_norm'):\n",
    "    Norm = _get_norm_layer(norm)\n",
    "\n",
    "    def _residual_block(x):\n",
    "        dim = x.shape[-1]\n",
    "        h = x\n",
    "        h = tf.pad(h, [[0, 0], [1, 1], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n",
    "        h = keras.layers.Conv3D(dim, 3, padding='valid', use_bias=False)(h)\n",
    "        h = Norm()(h)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = tf.pad(h, [[0, 0], [1, 1], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n",
    "        h = keras.layers.Conv3D(dim, 3, padding='valid', use_bias=False)(h)\n",
    "        h = Norm()(h)\n",
    "        return keras.layers.add([x, h])\n",
    "    # 0\n",
    "    h = inputs = keras.Input(shape=input_shape)\n",
    "    # 1\n",
    "    h = tf.pad(h, [[0, 0], [3, 3], [3, 3], [3, 3], [0, 0]], mode='REFLECT')\n",
    "    h = keras.layers.Conv3D(dim, 7, padding='valid', use_bias=False)(h)\n",
    "    h = Norm()(h)\n",
    "    h = tf.nn.relu(h)\n",
    "    # 2\n",
    "    for _ in range(n_downsamplings):\n",
    "        dim *= 2\n",
    "        h = keras.layers.Conv3D(dim, 3, strides=2, padding='same', use_bias=False)(h)\n",
    "        h = Norm()(h)\n",
    "        h = tf.nn.relu(h)\n",
    "    # 3\n",
    "    for _ in range(n_blocks):\n",
    "        h = _residual_block(h)\n",
    "    # 4\n",
    "    for _ in range(n_downsamplings):\n",
    "        dim //= 2\n",
    "        h = keras.layers.Conv3DTranspose(dim, 3, strides=2, padding='same', use_bias=False)(h)\n",
    "        h = Norm()(h)\n",
    "        h = tf.nn.relu(h)\n",
    "    # 5\n",
    "    h = tf.pad(h, [[0, 0], [3, 3], [3, 3], [3, 3], [0, 0]], mode='REFLECT')\n",
    "    h = keras.layers.Conv3D(output_channels, 7, padding='valid',activation='linear')(h)\n",
    "    return keras.Model(inputs=inputs, outputs=h)\n",
    "\n",
    "# define the convolutional discriminator\n",
    "def ConvDiscriminator(input_shape=(None, None, None, 1),\n",
    "                      dim=64,\n",
    "                      n_downsamplings=3,\n",
    "                      norm='instance_norm'):\n",
    "    dim_ = dim\n",
    "    Norm = _get_norm_layer(norm)\n",
    "    # 0\n",
    "    h = inputs = keras.Input(shape=input_shape)\n",
    "    # 1\n",
    "    h = keras.layers.Conv3D(dim, 4, strides=2, padding='same')(h)\n",
    "    h = tf.nn.leaky_relu(h, alpha=0.2)\n",
    "    for _ in range(n_downsamplings - 1):\n",
    "        dim = min(dim * 2, dim_ * 8)\n",
    "        h = keras.layers.Conv3D(dim, 4, strides=2, padding='same', use_bias=False)(h)\n",
    "        h = Norm()(h)\n",
    "        h = tf.nn.leaky_relu(h, alpha=0.2)\n",
    "    # 2\n",
    "    dim = min(dim * 2, dim_ * 8)\n",
    "    h = keras.layers.Conv3D(dim, 4, strides=1, padding='same', use_bias=False)(h)\n",
    "    h = Norm()(h)\n",
    "    h = tf.nn.leaky_relu(h, alpha=0.2)\n",
    "    # 3\n",
    "    h = keras.layers.Conv3D(1, 4, strides=1, padding='same')(h)\n",
    "    return keras.Model(inputs=inputs, outputs=h)\n",
    "\n",
    "# generators\n",
    "G_A2B = ResnetGenerator(input_shape=(height_crop_size,width_crop_size,slice_size,1))\n",
    "G_B2A = ResnetGenerator(input_shape=(height_crop_size,width_crop_size,slice_size,1))\n",
    "\n",
    "# discriminators\n",
    "D_A = ConvDiscriminator(input_shape=(height_crop_size,width_crop_size,slice_size,1))\n",
    "D_B = ConvDiscriminator(input_shape=(height_crop_size,width_crop_size,slice_size,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df600f",
   "metadata": {},
   "source": [
    "## define the loss functions and optimizers for generator and discriminator models\n",
    "each generator model is optimized via the combination of four outputs with four loss functions:\n",
    "\n",
    "    Adversarial loss (L2 or mean squared error).\n",
    "    Identity loss (L1 or mean absolute error).\n",
    "    Forward cycle loss (L1 or mean absolute error).\n",
    "    Backward cycle loss (L1 or mean absolute error).\n",
    "\n",
    "This can be achieved by defining a composite model used to train each generator model that is responsible for only updating the weights of that generator model, although it is required to share the weights with the related discriminator model and the other generator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lsgan_losses_fn():\n",
    "    mse = tf.losses.MeanSquaredError()\n",
    "    def d_loss_fn(r_logit, f_logit):\n",
    "        r_loss = mse(tf.ones_like(r_logit), r_logit)\n",
    "        f_loss = mse(tf.zeros_like(f_logit), f_logit)\n",
    "        return r_loss, f_loss\n",
    "    def g_loss_fn(f_logit):\n",
    "        f_loss = mse(tf.ones_like(f_logit), f_logit)\n",
    "        return f_loss\n",
    "    return d_loss_fn, g_loss_fn\n",
    "d_loss_fn, g_loss_fn = get_lsgan_losses_fn()\n",
    "cycle_loss_fn = tf.losses.MeanAbsoluteError()\n",
    "identity_loss_fn = tf.losses.MeanAbsoluteError()\n",
    "\n",
    "# define the learning rate decay schedule \n",
    "class LinearDecay(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    # if `step` < `step_decay`: use fixed learning rate\n",
    "    # else: linearly decay the learning rate to zero\n",
    "\n",
    "    def __init__(self, initial_learning_rate, total_steps, step_decay):\n",
    "        super(LinearDecay, self).__init__()\n",
    "        self._initial_learning_rate = initial_learning_rate\n",
    "        self._steps = total_steps\n",
    "        self._step_decay = step_decay\n",
    "        self.current_learning_rate = tf.Variable(initial_value=initial_learning_rate, trainable=False, dtype=tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        self.current_learning_rate.assign(tf.cond(\n",
    "            step >= self._step_decay,\n",
    "            true_fn=lambda: self._initial_learning_rate * (1 - 1 / (self._steps - self._step_decay) * (step - self._step_decay)),\n",
    "            false_fn=lambda: self._initial_learning_rate\n",
    "        ))\n",
    "        return self.current_learning_rate\n",
    "G_lr_scheduler = LinearDecay(lr, epochs * len_dataset, epoch_decay * len_dataset)\n",
    "D_lr_scheduler = LinearDecay(lr, epochs * len_dataset, epoch_decay * len_dataset)\n",
    "\n",
    "# define the generator and discriminator optimizers\n",
    "G_optimizer = keras.optimizers.Adam(learning_rate=G_lr_scheduler, beta_1=beta_1)\n",
    "D_optimizer = keras.optimizers.Adam(learning_rate=D_lr_scheduler, beta_1=beta_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c07064a",
   "metadata": {},
   "source": [
    "## training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a89912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the two generators are trained over the gradient loss, cycle loss, and identity loss\n",
    "@tf.function\n",
    "def train_G(A,B):\n",
    "    with tf.GradientTape() as t:\n",
    "        A2B = G_A2B(A, training=True)\n",
    "        B2A = G_B2A(B, training=True)\n",
    "        A2B2A = G_B2A(A2B, training=True)\n",
    "        B2A2B = G_A2B(B2A, training=True)\n",
    "        A2A = G_B2A(A, training=True)\n",
    "        B2B = G_A2B(B, training=True)\n",
    "        A2B_d_logits = D_B(A2B, training=True)\n",
    "        B2A_d_logits = D_A(B2A, training=True)\n",
    "        A2B_g_loss = g_loss_fn(A2B_d_logits)\n",
    "        B2A_g_loss = g_loss_fn(B2A_d_logits)\n",
    "        A2B2A_cycle_loss = cycle_loss_fn(A, A2B2A)\n",
    "        B2A2B_cycle_loss = cycle_loss_fn(B, B2A2B)\n",
    "        A2A_id_loss = identity_loss_fn(A, A2A)\n",
    "        B2B_id_loss = identity_loss_fn(B, B2B)\n",
    "        G_loss = (A2B_g_loss + B2A_g_loss) + (A2B2A_cycle_loss + B2A2B_cycle_loss) * cycle_loss_weight \\\n",
    "        + (A2A_id_loss + B2B_id_loss) * identity_loss_weight\n",
    "    G_grad = t.gradient(G_loss, G_A2B.trainable_variables + G_B2A.trainable_variables)\n",
    "    G_optimizer.apply_gradients(zip(G_grad, G_A2B.trainable_variables + G_B2A.trainable_variables))\n",
    "    return A2B, B2A, {'A2B_g_loss': A2B_g_loss,\n",
    "                      'B2A_g_loss': B2A_g_loss,\n",
    "                      'A2B2A_cycle_loss': A2B2A_cycle_loss,\n",
    "                      'B2A2B_cycle_loss': B2A2B_cycle_loss,\n",
    "                      'A2A_id_loss': A2A_id_loss,\n",
    "                      'B2B_id_loss': B2B_id_loss}\n",
    "\n",
    "# train the discriminators\n",
    "@tf.function\n",
    "def train_D(A, B, A2B, B2A):\n",
    "    with tf.GradientTape() as t:\n",
    "        A_d_logits = D_A(A, training=True)\n",
    "        B2A_d_logits = D_A(B2A, training=True)\n",
    "        B_d_logits = D_B(B, training=True)\n",
    "        A2B_d_logits = D_B(A2B, training=True)\n",
    "        A_d_loss, B2A_d_loss = d_loss_fn(A_d_logits, B2A_d_logits)\n",
    "        B_d_loss, A2B_d_loss = d_loss_fn(B_d_logits, A2B_d_logits)\n",
    "        D_A_gp = gan.gradient_penalty(functools.partial(D_A, training=True), A, \\\n",
    "                                      B2A, mode=gradient_penalty_mode)\n",
    "        D_B_gp = gan.gradient_penalty(functools.partial(D_B, training=True), B, \\\n",
    "                                      A2B, mode=gradient_penalty_mode)\n",
    "        D_loss = (A_d_loss + B2A_d_loss) + (B_d_loss + A2B_d_loss) + (D_A_gp + D_B_gp) \\\n",
    "        * gradient_penalty_weight\n",
    "    D_grad = t.gradient(D_loss, D_A.trainable_variables + D_B.trainable_variables)\n",
    "    D_optimizer.apply_gradients(zip(D_grad, D_A.trainable_variables + D_B.trainable_variables))\n",
    "    return {'A_d_loss': A_d_loss + B2A_d_loss,\n",
    "            'B_d_loss': B_d_loss + A2B_d_loss,\n",
    "            'D_A_gp': D_A_gp,\n",
    "            'D_B_gp': D_B_gp}\n",
    "\n",
    "# define a pool of fake samples\n",
    "class ItemPool:\n",
    "    def __init__(self, pool_size=50):\n",
    "        self.pool_size = pool_size\n",
    "        self.items = []\n",
    "    def __call__(self, in_items):\n",
    "        # `in_items` should be a batch tensor\n",
    "        if self.pool_size == 0:\n",
    "            return in_items\n",
    "        out_items = []\n",
    "        for in_item in in_items:\n",
    "            if len(self.items) < self.pool_size:\n",
    "                self.items.append(in_item)\n",
    "                out_items.append(in_item)\n",
    "            else:\n",
    "                if np.random.rand() > 0.5:\n",
    "                    idx = np.random.randint(0, len(self.items))\n",
    "                    out_item, self.items[idx] = self.items[idx], in_item\n",
    "                    out_items.append(out_item)\n",
    "                else:\n",
    "                    out_items.append(in_item)\n",
    "        return tf.stack(out_items, axis=0)\n",
    "A2B_pool = ItemPool(pool_size)\n",
    "B2A_pool = ItemPool(pool_size)\n",
    "\n",
    "def train_step(A, B):\n",
    "    A2B, B2A, G_loss_dict = train_G(A, B)\n",
    "    # cannot autograph `A2B_pool`\n",
    "    A2B = A2B_pool(A2B)  # or A2B = A2B_pool(A2B.numpy()), but it is much slower\n",
    "    B2A = B2A_pool(B2A)  # because of the communication between CPU and GPU\n",
    "    D_loss_dict = train_D(A, B, A2B, B2A)\n",
    "    return G_loss_dict, D_loss_dict\n",
    "\n",
    "@tf.function\n",
    "def sample(A, B):\n",
    "    A2B = G_A2B(A, training=False)\n",
    "    B2A = G_B2A(B, training=False)\n",
    "    A2B2A = G_B2A(A2B, training=False)\n",
    "    B2A2B = G_A2B(B2A, training=False)\n",
    "    return A2B, B2A, A2B2A, B2A2B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256deb41",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7606e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create  an output directory\n",
    "output_dir = './cycle_gan_output' # the directory to save the model outputs\n",
    "if not tf.io.gfile.isdir(output_dir):\n",
    "    tf.io.gfile.mkdir(output_dir) # if the output directory does not exist, creates it\n",
    "    \n",
    "# epoch counter\n",
    "ep_cnt = tf.Variable(initial_value=0,trainable=False,dtype=tf.int64)\n",
    "\n",
    "# checkpoint\n",
    "class Checkpoint:\n",
    "    \"\"\"Enhanced \"tf.train.Checkpoint\".\"\"\"\n",
    "    def __init__(self,\n",
    "                 checkpoint_kwargs,  # for \"tf.train.Checkpoint\"\n",
    "                 directory,  # for \"tf.train.CheckpointManager\"\n",
    "                 max_to_keep=5,\n",
    "                 keep_checkpoint_every_n_hours=None):\n",
    "        self.checkpoint = tf.train.Checkpoint(**checkpoint_kwargs)\n",
    "        self.manager = tf.train.CheckpointManager(self.checkpoint, directory, max_to_keep, keep_checkpoint_every_n_hours)\n",
    "    def restore(self, save_path=None):\n",
    "        save_path = self.manager.latest_checkpoint if save_path is None else save_path\n",
    "        return self.checkpoint.restore(save_path)\n",
    "    def save(self, file_prefix_or_checkpoint_number=None, session=None):\n",
    "        if isinstance(file_prefix_or_checkpoint_number, str):\n",
    "            return self.checkpoint.save(file_prefix_or_checkpoint_number, session=session)\n",
    "        else:\n",
    "            return self.manager.save(checkpoint_number=file_prefix_or_checkpoint_number)\n",
    "    def __getattr__(self, attr):\n",
    "        if hasattr(self.checkpoint, attr):\n",
    "            return getattr(self.checkpoint, attr)\n",
    "        elif hasattr(self.manager, attr):\n",
    "            return getattr(self.manager, attr)\n",
    "        else:\n",
    "            self.__getattribute__(attr)  # this will raise an exception\n",
    "\n",
    "checkpoint = Checkpoint(dict(G_A2B=G_A2B,\n",
    "                                G_B2A=G_B2A,\n",
    "                                D_A=D_A,\n",
    "                                D_B=D_B,\n",
    "                                G_optimizer=G_optimizer,\n",
    "                                D_optimizer=D_optimizer,\n",
    "                                ep_cnt=ep_cnt),\n",
    "                          py.join(output_dir,'checkpoints'),\n",
    "                          max_to_keep=5)\n",
    "try:  # restore checkpoint including the epoch counter\n",
    "     checkpoint.restore().assert_existing_objects_matched()\n",
    "except Exception as e:\n",
    "     print(e)\n",
    "        \n",
    "# summary\n",
    "def summary(name_data_dict,\n",
    "            step=None,\n",
    "            types=['mean', 'std', 'max', 'min', 'sparsity', 'histogram'],\n",
    "            historgram_buckets=None,\n",
    "            name='summary'):\n",
    "\n",
    "    def _summary(name, data):\n",
    "        if data.shape == ():\n",
    "            tf.summary.scalar(name, data, step=step)\n",
    "        else:\n",
    "            if 'mean' in types:\n",
    "                tf.summary.scalar(name + '-mean', tf.math.reduce_mean(data), step=step)\n",
    "            if 'std' in types:\n",
    "                tf.summary.scalar(name + '-std', tf.math.reduce_std(data), step=step)\n",
    "            if 'max' in types:\n",
    "                tf.summary.scalar(name + '-max', tf.math.reduce_max(data), step=step)\n",
    "            if 'min' in types:\n",
    "                tf.summary.scalar(name + '-min', tf.math.reduce_min(data), step=step)\n",
    "            if 'sparsity' in types:\n",
    "                tf.summary.scalar(name + '-sparsity', tf.math.zero_fraction(data), step=step)\n",
    "            if 'histogram' in types:\n",
    "                tf.summary.histogram(name, data, step=step, buckets=historgram_buckets)\n",
    "    with tf.name_scope(name):\n",
    "        for name, data in name_data_dict.items():\n",
    "            _summary(name, data)\n",
    "train_summary_writer = tf.summary.create_file_writer(tf.io.gfile.join(output_dir,'summaries'))\n",
    "\n",
    "# main loop\n",
    "with train_summary_writer.as_default():\n",
    "    for ep in tqdm.trange(epochs, desc='Epoch Loop', total=epochs):\n",
    "        if ep < ep_cnt:\n",
    "            continue\n",
    "        # update epoch counter\n",
    "        ep_cnt.assign_add(1)\n",
    "        # train for an epoch\n",
    "        for A, B in tqdm.tqdm(dataset_train, desc='Inner Epoch Loop', total=len_dataset):\n",
    "            G_loss_dict, D_loss_dict = train_step(A, B)\n",
    "            # summary\n",
    "            summary(G_loss_dict, step=G_optimizer.iterations, name='G_losses')\n",
    "            summary(D_loss_dict, step=G_optimizer.iterations, name='D_losses')\n",
    "            summary({'learning rate': G_lr_scheduler.current_learning_rate}, step=G_optimizer.iterations, \n",
    "                       name='learning rate')\n",
    "        for ii in range(len(Asample)):\n",
    "            A = tf.reshape(Asample[ii], (1,height_crop_size,width_crop_size,slice_size,1))\n",
    "            B = tf.reshape(Bsample[ii], (1,height_crop_size,width_crop_size,slice_size,1))\n",
    "            A2B, B2A, A2B2A, B2A2B = sample(A, B)\n",
    "            anatomy = np.squeeze(A.numpy())\n",
    "            flow = np.squeeze(B.numpy())\n",
    "            anatomy2flow = np.squeeze(A2B.numpy())  \n",
    "            flow2anatomy = np.squeeze(B2A.numpy())\n",
    "            anatomy2flow2anatomy = np.squeeze(A2B2A.numpy())\n",
    "            flow2anatomy2flow = np.squeeze(B2A2B.numpy()) \n",
    "            filename1 = py.join(sample_dir,'iter-%03u-%02u.mat' % (ep,ii))\n",
    "            scipy.io.savemat(filename1,{'anatomy':anatomy,\n",
    "                            'flow':flow,\n",
    "                            'anatomy2flow':anatomy2flow,\n",
    "                            'flow2anatomy':flow2anatomy,\n",
    "                            'anatomy2flow2anatomy':anatomy2flow2anatomy,\n",
    "                            'flow2anatomy2flow':flow2anatomy2flow})\n",
    "        # save checkpoint\n",
    "        checkpoint.save(ep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
